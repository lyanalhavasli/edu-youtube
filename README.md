# My ChatGpt Usage Data Analysis DSA 210 Project
## Description
This project focuses on analyzing my ChatGPT usage, leveraging data exported from ChatGPT in JSON format. The primary goal of this analysis is to uncover patterns and trends in my interactions with ChatGPT, offering insights into my usage behavior. Through visualizations and statistical analyses, the project explores the frequency and timing of queries across different days of the week and hours of the day, examines query distribution among various ChatGPT model versions, and investigates relationships between conversation lengths and the time spent on them. Bar charts, scatter plots, and other visual tools are used to highlight these patterns, while statistical tests, such as chi-square tests and correlation analyses, validate the findings.

## Motivation
The increasing reliance on AI-powered tools like ChatGPT in daily activities has sparked my interest in understanding how I personally interact with such technologies. By analyzing my ChatGPT interaction data, I aimed to uncover trends in the frequency and timing of queries, preferences for specific model versions, and the nature of my conversations. Through this analysis, I hope to gain insights into how I engage with AI tools, evaluate their impact on my productivity, and explore ways to optimize my usage for better outcomes. Additionally, this project demonstrates the power of data-driven approaches to understanding behavior, encouraging others to explore similar analyses for personal growth and reflection.

## Data Source
The data for this project was sourced from ChatGPT's conversation export feature, which provides interaction logs in JSON format. The dataset includes detailed information about each query, such as timestamps, message content, conversation duration, and metadata like the ChatGPT model version used. These structured logs allowed for a comprehensive analysis of my interactions with ChatGPT. The timestamps provided insights into the temporal patterns of my usage, while the metadata offered information about my preferences for different model versions. The data was preprocessed and cleaned to extract relevant features, such as the number of messages, time spent per conversation, and query lengths, enabling a detailed exploration of my ChatGPT usage behavior. This dataset forms the foundation for the visualizations, statistical analyses, and insights generated in this project.

## Data Analysis
The data analysis for this project involved several stages, combining various techniques to extract meaningful insights from the ChatGPT interaction dataset. The process began with data preprocessing, where the JSON data was parsed to extract relevant features such as timestamps, query content, conversation lengths, and model usage. This was followed by data cleaning, addressing any missing or inconsistent values to ensure the reliability of the analysis.

Next, exploratory data analysis (EDA) was conducted using visualizations, such as bar charts and scatter plots, to identify trends and patterns. Temporal analysis highlighted query distributions across days of the week and hours of the day, while model-specific analysis examined the usage of different ChatGPT versions. Correlation analysis was employed to investigate relationships between conversation duration and the number of messages exchanged.

To validate observations, statistical hypothesis testing was used, including chi-square tests for categorical distributions and Pearson correlation tests for continuous relationships. These techniques ensured that the conclusions drawn were statistically significant and data-driven. This multi-stage analysis approach provided a holistic understanding of my ChatGPT usage patterns, from raw data processing to deriving actionable insights.

## Findings





